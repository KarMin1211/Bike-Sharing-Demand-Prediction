---
title: "Bike Sharing System Analysis in South Korea"
author: "Tan Kar Min"
date: "2023-11-26"
output: rmarkdown::github_document
---

Import Essential Libraries
```{r}
library(rvest)
library(httr)
library(tidyverse)
library(ggplot2)
library(ggpubr)
library(chron)
library(fastDummies)
library(BBmisc)
library(car)
library(openmeteo)
library(lubridate)
```

## Data Collection

Retrieve the population information for South Korean cities from an HTML table and transform it into a data frame.
```{r}
url <- "https://worldpopulationreview.com/countries/cities/south-korea"
root_node <- read_html(url)
table_nodes <- html_nodes(root_node, "table")
kr_cities<-html_table(table_nodes[[1]], fill=TRUE)
head(kr_cities)
```

Extract South Korea bike sharing systems HTML table from a Wiki page and convert it into a data frame.
```{r}
url <- "https://en.wikipedia.org/wiki/Public_bicycle_rental_service_in_South_Korea"
root_node <- read_html(url)
table_nodes <- html_nodes(root_node, "table")
bike_sharing_systems<-html_table(table_nodes[[3]], fill=TRUE)
bike_sharing_systems<-select(bike_sharing_systems, -`Nat.`)
head(bike_sharing_systems)
```

Download a specific hourly Seoul bike sharing demand dataset which will be used to train our model.
```{r}
seoul_bike_sharing<-read.csv("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-RP0321EN-SkillsNetwork/labs/datasets/raw_seoul_bike_sharing.csv")
head(seoul_bike_sharing)
```
The data set consist of the following features:
- `TEMPERATURE` - Temperature in Celsius
- `HUMIDITY` - Unit is `%`
- `WIND_SPEED` - Unit is `m/s`
- `VISIBILITY` - Multiplied by 10m
- `DEW_POINT_TEMPERATURE` - The temperature to which the air would have to cool down in order to reach saturation, unit is Celsius
- `SOLAR_RADIATION` - MJ/m2
- `RAINFALL` - mm
- `SNOWFALL` - cm
- `DATE` - Year-month-day
- `HOUR`- Hour of he day
- `FUNCTIONAL DAY` - NoFunc(Non Functional Hours), Fun(Functional hours)
- `HOLIDAY` - Holiday/No holiday
- `SEASONS` - Winter, Spring, Summer, Autumn
</br>

## Date Cleaning

Standardize all column names
```{r}
 names(kr_cities)<-str_replace_all(toupper(names(kr_cities)), " ", "_")
 names(bike_sharing_systems)<-str_replace_all(toupper(names(bike_sharing_systems)), " ", "_")
 names(seoul_bike_sharing)<-str_replace_all(toupper(names(seoul_bike_sharing)), " ", "_")
```


Clean kr_cities dataset to match the cities name of bike_sharing_systems table.
```{r}
kr_cities$CITY <- sub("-[a-z]+", "", kr_cities$CITY)
kr_cities$`2023_POPULATION`<-as.numeric(gsub(",", "", kr_cities$`2023_POPULATION`))
head(kr_cities)
```

Clean Seoul bike sharing dataset
```{R}
summary(seoul_bike_sharing)
dim(seoul_bike_sharing)
```
The data set have 14 features and 8760 records. "RENTED_BIKE_COUNT" and "TEMPERATURE" have missing values. 

</br>

Handling missing values in RENTED_BIKE_COUNT by dropping them
```{r}
seoul_bike_sharing <-seoul_bike_sharing[!is.na(seoul_bike_sharing$RENTED_BIKE_COUNT),]
dim(seoul_bike_sharing)
```

Handling missing values in TEMPERATURE by replacing them with average temperature
```{r}
seoul_bike_sharing %>% 
  filter(is.na(TEMPERATURE)) 
```
All missing temperature are found to be in Summer. 

</br>

Replace NA values with average temperature of summer
```{r}
Avg_temp<-aggregate(TEMPERATURE~SEASONS, seoul_bike_sharing, mean, na.action=na.omit)
round(Avg_temp[Avg_temp$SEASONS=="Summer", "TEMPERATURE"], 1)
seoul_bike_sharing <- seoul_bike_sharing %>%
  mutate(TEMPERATURE = ifelse(is.na(TEMPERATURE), 26.6, TEMPERATURE))

summary(seoul_bike_sharing)
```

Check datatypes
```{r}
str(seoul_bike_sharing)
```

Several datatypes needs to be coerce. Change "DATE" and "HOUR" to date and ordinal datatype respectively. 
```{r}
seoul_bike_sharing$DATE<-as.Date(seoul_bike_sharing$DATE, format = "%d/%m/%Y")
class(seoul_bike_sharing$DATE)

seoul_bike_sharing$HOUR<-as.factor(seoul_bike_sharing$HOUR)
class(seoul_bike_sharing$HOUR)
```

## Explanatory Data Analysis

### Descriptive Analysis

Basic Observations:
```{r}
summary(seoul_bike_sharing)
table(seoul_bike_sharing$SEASONS)
table(seoul_bike_sharing$HOLIDAY)
table(seoul_bike_sharing$FUNCTIONING_DAY)
```
1) We can see from `DATE` that we have exactly a full year of data
2) Temperature has a large range, so we might expect it to explain at least some of the variation in bike rentals
3) Precipitation seems to be quite rare
4) Wind speed has a small range. The average `WINDSPEED` is very light at only 1.7 m/s 
5) Spring and Winter have the same count of records, while autumn has the least and Summer has the most
6) Majorities of the records are not holidays. 
7) All records are functioning day, thus, we can remove this feature from our analysis

</br>

Check correlation
```{r}
cor_matrix<-cor(seoul_bike_sharing[c(2,4,5,6,7,8,9,10,11)])
cor_matrix
```
A multicollinearity issue has surfaced in the data, marked by a notable correlation between TEMPERATURE and DEW_POINT_TEMPERATURE. Additionally, Solar Radiation exhibits a noteworthy correlation with both HUMIDITY and WIND_SPEED. 

Among all the features, the variables 'TEMPERATURE' and 'DEW_POINT_TEMPERATURE' exhibit the highest correlation with 'RENTED_BIKE_COUNT', followed by 'SOLAR_RADIATION', 'VISIBILITY', and 'HUMIDITY'. However, it is necessary to validate these correlations through visual aids for a more comprehensive understanding.

</br>

### Data Visualisation

Distribution of `RENTED_BIKE_COUNT`
```{R}
ggplot(seoul_bike_sharing, aes(x=RENTED_BIKE_COUNT))+
  geom_histogram(fill="lightgray", color="black")
```
</br> 

The mode of bikes rented is about 250. The distribution is right skewed. 

</br> 

Association between `RENTED_BIKE_COUNT` and `TEMPERATURE`.
```{r}
ggplot(seoul_bike_sharing, aes(TEMPERATURE,RENTED_BIKE_COUNT)) + 
  geom_point()+
  geom_smooth(method="lm", formula = y ~ poly(x, 4), se = FALSE)
```

</br> 

It seems that there is a non-linear positive relationship, possibly a fourth-degree polynomial, between the two variables. `RENTED_BIKE_COUNT` peaks at around 25 degrees Celsius.

</br>

Association between `RENTED_BIKE_COUNT` and `HUMIDITY`
```{r}
ggplot(seoul_bike_sharing, aes(HUMIDITY,RENTED_BIKE_COUNT)) + 
  geom_point()+
  geom_smooth(method="lm", formula = y ~ poly(x, 2), se = FALSE)
```

</br> 

It appears that there is a weak non-linear relationship between `HUMIDITY` and `RENTED_BIKE_COUNT`. Moderate humidity levels tend to be associated with a greater number of rented bikes.

</br>

Association between `RENTED_BIKE_COUNT` and `WIND_SPEED`
```{r}
ggplot(seoul_bike_sharing, aes(WIND_SPEED,RENTED_BIKE_COUNT)) + 
  geom_point()
```

</br> 

Not much association can be observed between `WIND_SPEED` and `RENTED_BIKE_COUNT`.

</br>

Association between `RENTED_BIKE_COUNT` and `VISIBILITY`
```{r}
ggplot(seoul_bike_sharing, aes(VISIBILITY,RENTED_BIKE_COUNT)) + 
  geom_point()
```

</br> 

Not much association can be observed between `VISIBILITY` and `RENTED_BIKE_COUNT`.

</br>

Association between `RENTED_BIKE_COUNT` and `DEW_POINT_TEMPERATURE`
```{r}
ggplot(seoul_bike_sharing, aes(DEW_POINT_TEMPERATURE,RENTED_BIKE_COUNT)) + 
  geom_point()
```

</br> 

The relationship between `RENTED_BIKE_COUNT` and `DEW_POINT_TEMPERATURE` is similar to that between `RENTED_BIKE_COUNT` and `TEMPERATURE`.This is expected as `TEMPERATURE` and `DEW_POINT_TEMPERATURE` have very high correlation. Thus, we can exclude one of the features in our model later.

</br>

Association between `RENTED_BIKE_COUNT` and `SOLAR_RADIATION  `
```{r}
ggplot(seoul_bike_sharing, aes(SOLAR_RADIATION,RENTED_BIKE_COUNT)) + 
  geom_point()
```

</br> 

There is a very weak negative relationship between the two variables. 

</br>

Association between `RENTED_BIKE_COUNT` and `RAINFALL  `
```{r}
ggplot(seoul_bike_sharing, aes(RAINFALL,RENTED_BIKE_COUNT)) + 
  geom_point()

df_rain<-seoul_bike_sharing%>%
  group_by(RAINFALL)%>%
  summarise(AVG_BIKE=mean(RENTED_BIKE_COUNT))

ggplot(df_rain, aes(RAINFALL, AVG_BIKE))+
  geom_point()+
  labs(title = "Average Rented Bikes by Rainfall")
```

</br> 

The average number of rented bikes is significantly larger when there are no rainfall or very minimal rainfall. 

</br>

Association between `RENTED_BIKE_COUNT` and `SNOWFALL  `
```{r}
ggplot(seoul_bike_sharing, aes(SNOWFALL,RENTED_BIKE_COUNT)) + 
  geom_point()

df_rain<-seoul_bike_sharing%>%
  group_by(SNOWFALL)%>%
  summarise(AVG_BIKE=mean(RENTED_BIKE_COUNT))

ggplot(df_rain, aes(SNOWFALL, AVG_BIKE))+
  geom_point()+
  labs(title = "Average Rented Bikes by Snowfall")
```

</br> 

Similar to `RAINFALL`, the average number of rented bikes significantly increases in the absence of snowfall. The average number of rented bikes remains relatively similar(low) during snowfall.

</br>

Association between rented bike count with day and time
```{r}
ggplot(seoul_bike_sharing, aes(DATE, RENTED_BIKE_COUNT, color=HOUR))+
  geom_point(alpha=0.8)
```
</br> 

1) The number of rented bikes reaches its peak around mid-year and October, while it tends to be lower before April. This pattern suggests an association with the seasons, where mid-year and October align with spring/summer and autumn, respectively, while the period before April corresponds to winter.

2) The number of rented bikes appears to be associated with time. There is a notable peak during the evening around 6 pm, followed by another peak in the morning around 8 am.

</br>

Let's delve into a more comprehensive analysis of the relationship between the number of rented bikes and the factors of seasons and time
```{r}
ggplot(seoul_bike_sharing, aes(HOUR, RENTED_BIKE_COUNT))+
  geom_boxplot()+
  facet_wrap(~seoul_bike_sharing$SEASONS)
```
</br> 

The overall scale of bike rental counts does indeed vary with the seasons. Summer tends to have slightly higher average number of rented bike than spring and autumn, which exhibit a very similar scale. In contrast, winter has a substantially lower scale compared to the other three seasons. Despite these differences in scale, key patterns remain remarkably consistent. For instance, peak demand times persist at 8 am and 6 pm across all seasons

</br>

Let's explore whether holidays have an impact on the number of rented bikes.
```{r}
t.test(RENTED_BIKE_COUNT ~ HOLIDAY, data = seoul_bike_sharing)
```
On average, the number of rented bikes is significantly higher on non-holidays compared to holidays.

</br>

Additionally, we analyze how weekdays and weekends influence the demand for bike rentals.
```{r}
seoul_bike_sharing$IS_WEEKEND<-ifelse(is.weekend(seoul_bike_sharing$DATE), 1, 0)
t.test(RENTED_BIKE_COUNT ~ IS_WEEKEND, data = seoul_bike_sharing)
```
On average, the number of rented bikes is significantly higher on weekdays compared to weekends. Hence, we will include this additional feature in our analysis.

</br>

## Baseline Predictive Modelling

We will first remove unused columns. We won't be using the `DATE` column, because 'as is', it basically acts like an data entry index. We also do not need the `FUNCTIONAL DAY` column because it only has one distinct value remaining.
```{r}
df_removed <- seoul_bike_sharing %>% 
  select(-DATE, -FUNCTIONING_DAY) 
```

Convert categorical/ordinal attributes to dummy variables. 
```{r}
df_converted <- dummy_cols(df_removed, 
                           select_columns = c("SEASONS", "HOLIDAY", "HOUR"),
                           remove_first_dummy = TRUE)%>%
                select(-SEASONS, -HOLIDAY,-HOUR)

####Standardized column names again
names(df_converted)<-toupper(names(df_converted))
names(df_converted)<-str_replace_all(names(df_converted), " ", "_")
head(df_converted)
```

Scale and Normalize numerical data 
```{r}
df_final<- df_converted %>% 
 mutate_at(c('TEMPERATURE', 'HUMIDITY', 'WIND_SPEED', 'VISIBILITY', 'DEW_POINT_TEMPERATURE', 'SOLAR_RADIATION', 'RAINFALL', 'SNOWFALL'), ~(normalize(.,method = "range", range = c(0, 1)) %>% as.vector))
summary(df_final)
```

Based on EDA and prior knowledge, weather conditions may affect people's bike renting. Thus, we will build a model to explain the city's bike-sharing demand based on its local weather information.
```{r}
df1<-df_final%>%
  select(RENTED_BIKE_COUNT,TEMPERATURE, HUMIDITY, WIND_SPEED, VISIBILITY, DEW_POINT_TEMPERATURE, SOLAR_RADIATION, RAINFALL, SNOWFALL)

lm_model_weather<-lm(RENTED_BIKE_COUNT~.,df1)
summary(lm_model_weather)
```
The adjusted R-squared suggests that the weather model explains 43.2% of the data variability. `VISIBILITY` and `DEW_POINT_TEMPERATURE` are not significant. 

</br>

Based on EDA, it appears that additional features such as seasons or time could also be influential predictors of bike rental demand. Consequently, we will construct another model incorporating all features and compare its performance with the weather-based model.
```{r}
df2<-df_final%>%
 select(everything()) 

lm_model_all<-lm(RENTED_BIKE_COUNT ~ ., df2)
summary(lm_model_all)
```
The current model outperforms the previous one based on the adjusted R-squared, suggesting that both weather conditions and time are significant predictors. As anticipated, `WIND_SPEED` and `VISIBILITY` are not deemed significant, as their association with `RENTED_BIKE_COUNT` lacks statistical significance, as observed in the exploratory data analysis (EDA).

</br> 

## Refine the Regression Model

To enhance the lm_model_all model, which exhibits a higher adjusted R-squared, we will address the issue of multicollinearity observed in the Exploratory Data Analysis (EDA). We will exclude one of the highly correlated variables.
```{r}
#we exclude DEW_POINT_TEMPERATURE that is highly correlated with TEMPERATURE and SOLAR_RADIATION that exhibits a noteworthy correlation with both HUMIDITY and WIND_SPEED. 
vif(lm_model_all)
vif(lm(RENTED_BIKE_COUNT ~ .-DEW_POINT_TEMPERATURE-SOLAR_RADIATION, df2))
```
Upon removing correlated variables, the VIF values have substantially decreased, and the remaining variables now exhibit acceptable VIF values, all equal to or below 5.

</br> 

In the lm_model_all, it is evident that several HOUR dummy variables are insignificant. Consequently, we merge some of them based on their coefficient sizes. We also remove correlated and insignificant variables. 
```{r}
df3 <- df_final %>%
  mutate(HOUR_9_16 = HOUR_9 + HOUR_16,
         HOUR_15_1_12_13_14 =  HOUR_15 + HOUR_1 + HOUR_12+ HOUR_13 + HOUR_14) %>%
  select(-HOUR_1, -HOUR_15, -HOUR_9, -HOUR_16, -HOUR_12, -HOUR_13 , -HOUR_14, -WIND_SPEED, -VISIBILITY, -DEW_POINT_TEMPERATURE, -SOLAR_RADIATION)
```


We will utilize the 'glm' function, which provides the AIC measurement for more robust comparisons. The chosen distribution is Gaussian, and the identity link is employed, equivalent to linear regression.
```{r}
lm_model_all_refined1<-glm(RENTED_BIKE_COUNT ~ ., family=gaussian(link = "identity"),df3)
summary(lm_model_all_refined1)

AIC(lm_model_all_refined1)
BIC(lm_model_all_refined1)

phi=summary(lm_model_all_refined1)$dispersion
qqnorm(residuals(lm_model_all_refined1, type="deviance")/sqrt(phi))
qqline(residuals(lm_model_all_refined1, type="deviance")/sqrt(phi))


plot(fitted(lm_model_all_refined1), residuals(lm_model_all_refined1, type="deviance")/sqrt(phi),
xlab="fitted values",
ylab="standardised residuals")
```

</br>

All variables are statistically significant. However, the Q-Q plot reveals slight deviations at both ends, and the residual plot displays noticeable patterns. These observations suggest that modifications to the model are necessary.

</br> 

In the EDA, we observed that the relationships between TEMPERATURE and RENTED_BIKE_COUNT and between HUMIDITY and RENTED_BIKE_COUNT are not linear. Thus, we will introduce polynomial forms to assess whether it improves the model.
```{r}
lm_model_all_refined2<-glm(RENTED_BIKE_COUNT ~ poly(TEMPERATURE, 4)+poly(HUMIDITY, 2)+., family=gaussian(link = "identity"), df3)
summary(lm_model_all_refined2)

AIC(lm_model_all_refined2)
BIC(lm_model_all_refined2)

phi=summary(lm_model_all_refined2)$dispersion
qqnorm(residuals(lm_model_all_refined2, type="deviance")/sqrt(phi))
qqline(residuals(lm_model_all_refined2, type="deviance")/sqrt(phi))


plot(fitted(lm_model_all_refined2), residuals(lm_model_all_refined2, type="deviance")/sqrt(phi),
xlab="fitted values",
ylab="standardised residuals")
```

</br>

The introduction of polynomial forms led to an improvement in the AIC and BIC despite having one variable becoming insignificant. The Q-Q plot and residual plot show similar patterns, indicating that further adjustments to the model may be needed.

</br> 

Based on EDA, we noted a significant increase in the number of rented bikes when it is not raining or snowing. Consequently, we have transformed the two variables into categorical variables, distinguishing between raining or not raining and snowing or not snowing.
```{r}
df4<-df3
df4$NO_RAINING<-ifelse(df3$RAINFALL==0, 1, 0)
df4$NO_SNOWFALL<-ifelse(df3$SNOWFALL==0, 1, 0)
df4 <- df4%>%
  select(-RAINFALL, -SNOWFALL)
```


```{r}
lm_model_all_refined3<-glm(RENTED_BIKE_COUNT ~ poly(TEMPERATURE, 4)+poly(HUMIDITY, 2)+., family=gaussian(link = "identity"), df4)
summary(lm_model_all_refined3)

AIC(lm_model_all_refined3)
BIC(lm_model_all_refined3)

phi=summary(lm_model_all_refined3)$dispersion
qqnorm(residuals(lm_model_all_refined3, type="deviance")/sqrt(phi))
qqline(residuals(lm_model_all_refined3, type="deviance")/sqrt(phi))


plot(fitted(lm_model_all_refined3), residuals(lm_model_all_refined3, type="deviance")/sqrt(phi),
xlab="fitted values",
ylab="standardised residuals")
```
</br>

The model performance is very similar to the previous version with an improved AIC and BIC. 

</br> 

Based on EDA, we observed that summer, spring, and autumn exhibit a similar scale in rented bike counts. To simplify the model, we will attempt to merge these three categories into one.
```{r}
lm_model_all_refined4<-glm(RENTED_BIKE_COUNT ~ poly(TEMPERATURE, 4)+poly(HUMIDITY, 2)+.-SEASONS_SUMMER-SEASONS_SPRING, family=gaussian(link = "identity"), df4)

summary(lm_model_all_refined4)

AIC(lm_model_all_refined4)
BIC(lm_model_all_refined4)

phi=summary(lm_model_all_refined4)$dispersion
qqnorm(residuals(lm_model_all_refined4, type="deviance")/sqrt(phi))
qqline(residuals(lm_model_all_refined4, type="deviance")/sqrt(phi))


plot(fitted(lm_model_all_refined4), residuals(lm_model_all_refined4, type="deviance")/sqrt(phi),
xlab="fitted values",
ylab="standardised residuals")
```
</br>

The AIC and BIC has increased, and the Q-Q plot and residual plot remain unchanged. Therefore, we will stick to the previous model.

</br> 

We noted variations in the number of rented bikes according to different periods of time. Therefore, we will attempt to simplify the model by categorizing the hours into five distinct periods. we will merge the DAWN category with the baseline dummy variable (HOUR_0).
```{r}
df5 <- df_final %>%
  mutate(DAWN = HOUR_1 + HOUR_2 +HOUR_3 + HOUR_4 + HOUR_5,
         MORNING = HOUR_6 + HOUR_7 + HOUR_8, 
         MIDDLE =  HOUR_9 + HOUR_10 + HOUR_11+ HOUR_12 + HOUR_13 + HOUR_14 + HOUR_15,
         EVENING = HOUR_16 + HOUR_17 + HOUR_18 + HOUR_19 + HOUR_20,
         NIGHT = HOUR_21 + HOUR_22 + HOUR_23) %>%
  select(-WIND_SPEED, -VISIBILITY, -DEW_POINT_TEMPERATURE, -SOLAR_RADIATION, -DAWN, -starts_with("HOUR"), )
df5$NO_RAINING<-ifelse(df5$RAINFALL==0, 1, 0)
df5$NO_SNOWFALL<-ifelse(df5$SNOWFALL==0, 1, 0)
df5 <- df5%>%
  select(-RAINFALL, -SNOWFALL)
head(df5)
```

```{r}
lm_model_all_refined5<-glm(RENTED_BIKE_COUNT ~ poly(TEMPERATURE, 4)+poly(HUMIDITY, 2)+., family=gaussian(link = "identity"), df5)
summary(lm_model_all_refined5)

AIC(lm_model_all_refined5)
BIC(lm_model_all_refined5)

phi=summary(lm_model_all_refined5)$dispersion
qqnorm(residuals(lm_model_all_refined5, type="deviance")/sqrt(phi))
qqline(residuals(lm_model_all_refined5, type="deviance")/sqrt(phi))


plot(fitted(lm_model_all_refined5), residuals(lm_model_all_refined5, type="deviance")/sqrt(phi),
xlab="fitted values",
ylab="standardised residuals")
```

</br>

While the lower tail of the Q-Q plot has shown improvement comparing with lm_model_refined3, there is a slight increase in the AIC and BIC, and the residuals still do not exhibit a randomly scattered pattern. To maintain the simplicity of the model, We can try to improve this model by using link functions and a different distribution

</br> 

Earlier, we observed a positive skewness in the response variable (RENTED_BIKE_COUNT). To address this skewness, we introduced a log link to explore potential improvements.
```{r}
lm_model_all_refined6<-glm(RENTED_BIKE_COUNT ~ poly(TEMPERATURE, 4)+poly(HUMIDITY, 2)+., family=gaussian(link = "log"), df5)
summary(lm_model_all_refined6)

AIC(lm_model_all_refined6)
BIC(lm_model_all_refined6)

phi=summary(lm_model_all_refined6)$dispersion
qqnorm(residuals(lm_model_all_refined6, type="deviance")/sqrt(phi))
qqline(residuals(lm_model_all_refined6, type="deviance")/sqrt(phi))


plot(fitted(lm_model_all_refined6), residuals(lm_model_all_refined6, type="deviance")/sqrt(phi),
xlab="fitted values",
ylab="standardised residuals")
```
</br>

The AIC and BIC significantly improved after adding a log link. The residual plot also significantly improved by showing a relatively randomly scattered pattern. The Q-Q plot on the other hand shows a greater deviation of the tails and several variables are not significant. 

</br> 

Let's check if the Gaussian distribution is a suitable fit. 
```{r}
plot(fitted(lm_model_all_refined6), abs(residuals(lm_model_all_refined6, type="deviance")/sqrt(phi)),
xlab="scaled fitted values",
ylab="absolute standardised residuals")
s=fitted(lm_model_all_refined6)
t= abs(residuals(lm_model_all_refined6, type="deviance")/sqrt(phi))
fit<-lm(t~s)
abline(fit,col=2)
```
</br>

The observation of a positive trend indicates that the variance function is assumed to increase too slowly with the mean. Consequently, it suggests considering distributions with a greater variance function.

</br> 

Let's try using the Poisson distribution.
```{r}
lm_model_all_refined7<-glm(RENTED_BIKE_COUNT ~ poly(TEMPERATURE, 4)+poly(HUMIDITY, 2)+., family=poisson(link = "log"), df5)
summary(lm_model_all_refined7)

phi=summary(lm_model_all_refined7)$dispersion
qqnorm(residuals(lm_model_all_refined7, type="deviance")/sqrt(phi))
qqline(residuals(lm_model_all_refined7, type="deviance")/sqrt(phi))


plot(fitted(lm_model_all_refined7), residuals(lm_model_all_refined7, type="deviance")/sqrt(phi),
xlab="fitted values",
ylab="standardised residuals")
```
</br>

All variables are significant and the residuals are relatively randomly scattered.There is slight deviation in the Q-Q plot.  

</br> 

Let's check if the Poisson distribution is a suitable fit. 
```{r}
plot(2*sqrt(fitted(lm_model_all_refined7)), abs(residuals(lm_model_all_refined7, type="deviance")/sqrt(phi)),
xlab="scaled fitted values",
ylab="absolute standardised residuals")
s=2*sqrt(fitted(lm_model_all_refined7))
t= abs(residuals(lm_model_all_refined7, type="deviance")/sqrt(phi))
fit<-lm(t~s)
abline(fit,col=2)
```
</br>

No significant trend can be seen. This indicates that the Poisson distribution is a suitable choice. 

Therefore, we will employ this model as our final model for predicting bike renting demand in South Korea. 


```{r}
save(lm_model_all_refined7, file="bike_pred_model_final.rda")
```

## Prediction

Now, we'll employ the regression model built earlier to forecast bike rental demand for the upcoming five days. Subsequently, the following script will be utilized as a data source to construct a Power BI dashboard.

First, we'll integrate the Public Holiday API provided by Abstract API to gather information on holidays, which is one of the predictors in our model.
```{r}
readRenviron(".env")
holiday_url<- 'https://holidays.abstractapi.com/v1/'
holidays<-c()
dates <- as.character(seq(Sys.Date() + 1, Sys.Date() + 5, by = "days"))
  
  for (datex in dates) {
    holiday_query <- list(api_key = Sys.getenv("holidays_api_key"), 
    country = "KR", year = year(datex), month = month(datex), day= mday(datex))
    response <- GET(holiday_url, query= holiday_query)
    json_result <- content(response, as="parsed")
    
    if (length(json_result) != 0) {
      holidays<-append(holidays,json_result[[1]]$date)
    }
    
    Sys.sleep(1) #limitation of API
  }
  
holidays
```
Next, we create a function designed to assemble the prediction dataset and apply it to our model, resulting in forecasted bike rentals.
```{r}

prediction<-function(city){
#get weather forecast
temp<-weather_forecast( city,
                        Sys.Date()+1,
                        Sys.Date()+5,
                        hourly = c("temperature_2m", "relative_humidity_2m", "rain",  "snowfall"),
                        response_units = list(temperature_unit = "celsius"),
                        timezone = "UTC")

#format collected data
temp<-as.data.frame(temp)
colnames(temp)<-c("DATE", "TEMPERATURE", "HUMIDITY", "RAINFALL", "SNOWFALL")

temp$HOUR <- as.character(as.numeric(format(as.POSIXct(temp$DATE), format = "%H"))) 
temp$DATE <- as.Date(temp$DATE, tz = "UTC")
temp$CITY <- city
temp$WEEKEND<-ifelse(is.weekend(temp$DATE), "Weekend" , "Weekday")
temp$SEASONS<-ifelse(month(temp$DATE) %in% c(4,5,6), "Spring",
                ifelse(month(temp$DATE) %in% c(7,8), "Summer",
                ifelse(month(temp$DATE) %in% c(9,10,11), "Autumn",
                "Winter")))
#Use API to determine holidays  
temp$HOLIDAY<-ifelse(temp$DATE %in% holidays, "Holiday", "No Holiday")


#Format data set to match the train data to fit the model
temp_final <- dummy_cols(temp, 
        select_columns = c("HOUR"),
        remove_first_dummy = TRUE)

temp_final$SEASONS_SUMMER<-ifelse(temp$SEASONS=='Summer', 1, 0)
temp_final$SEASONS_SPRING<-ifelse(temp$SEASONS=='Spring', 1, 0)
temp_final$SEASONS_WINTER<-ifelse(temp$SEASONS=='Winter', 1, 0)
temp_final$HOLIDAY_NO_HOLIDAY<-ifelse(temp$HOLIDAY=='No Holiday', 1, 0)
temp_final$IS_WEEKEND<-ifelse(temp$WEEKEND=='Weekend', 1, 0)

temp_final$NO_RAINING<-ifelse(temp$RAINFALL==0, 1, 0)
temp_final$NO_SNOWFALL<-ifelse(temp$SNOWFALL==0, 1, 0)

temp_final_pred <- temp_final %>%
  mutate(DAWN = HOUR_1 + HOUR_2 +HOUR_3 + HOUR_4 + HOUR_5,
         MORNING = HOUR_6 + HOUR_7 + HOUR_8, 
         MIDDLE =  HOUR_9 + HOUR_10 + HOUR_11+ HOUR_12 + HOUR_13 + HOUR_14 + HOUR_15,
         EVENING = HOUR_16 + HOUR_17 + HOUR_18 + HOUR_19 + HOUR_20,
         NIGHT = HOUR_21 + HOUR_22 + HOUR_23) %>%
  mutate(TEMPERATURE = (TEMPERATURE - (-17.8)) / (39.4 - (-17.8)),#min max of training data
         HUMIDITY = (HUMIDITY - 0) / (98-0))%>% #min max of training data
  select(-DAWN, -starts_with("HOUR"), -DATE, -RAINFALL, -SNOWFALL, -SEASONS, -WEEKEND, -CITY)

pred<-predict(lm_model_all_refined7, temp_final_pred)
pred<-pmin(round(exp(pred)), 50000) 
#As per information online, Seoul have the maximum number of bikes for sharing which is      around 45,000. Hence, to prevent unrealistic prediction, the number predicted will be        capped at 50,000
    
final<-cbind(temp, pred)

    return(final)
}
```


```{r}
KR_BIKE_PRED<-prediction("Seoul")

head(KR_BIKE_PRED)
```

Apart from Seoul, there are several other cities in South Korea with bike-sharing systems. We also try to provide insights into four other major cities with bike-sharing systems using our model. We begin by acquiring the population size of these cities which will be used to normalize our predictions, enhancing the accuracy of our forecasts.
```{r}
other_cities<-left_join(bike_sharing_systems, kr_cities, by=c("REGION"="CITY"))%>%
  arrange(desc(`2023_POPULATION`))%>%
  head(5) #select top 4 biggest cities other than Seoul

cities<-as.vector(other_cities$REGION)
populations<-as.vector(other_cities$`2023_POPULATION`)

cities
populations
```
We utilize the model to forecast bike rental demands for the next five days in the four additional cities, adjusting the predictions based on their respective population sizes.

It's crucial to acknowledge that these predictions only serve as preliminary insights into the demands, as various additional factors may differ between cities, impacting the accuracy of the forecasts.
```{r}
for (i in c(2:length(cities))) {
  x<-prediction(cities[i])
  x$pred<-pmin(round((x$pred/populations[1])*populations[i],0), 50000)
  KR_BIKE_PRED<-rbind(KR_BIKE_PRED,x)
}

head(KR_BIKE_PRED)
```
The resulting dataset will be used to build a dashboard using Power BI for presenting purposes.



